version: '3.8'

services:
  ml_api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
    environment:
      - TF_FORCE_GPU_ALLOW_GROWTH=true  # Helps with GPU memory management
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # Enable if using GPU 